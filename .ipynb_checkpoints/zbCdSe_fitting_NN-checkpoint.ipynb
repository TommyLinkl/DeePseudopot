{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "561d133a-1515-4b7d-9848-b28a49178cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits import mplot3d\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "torch.manual_seed(24)\n",
    "\n",
    "MASS = 1.0\n",
    "HBAR = 1.0\n",
    "AUTOEV = 27.2114\n",
    "AUTONM = 0.05291772108\n",
    "\n",
    "# qGrid: 0.0 to 5.0; NGRID = 1024; \n",
    "# rGrid: 0.0 to 0.02*TWOPI / (NGRID * dq)    --> 0.0 to 25.7108; NGRID = 1024; \n",
    "NQGRID = 2048\n",
    "qGrid = torch.linspace(0.0, 10.0, NQGRID, dtype=torch.float64)\n",
    "dq = (10.0-0.0)/NQGRID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8246ad3e-7084-40c1-8463-19b871c33914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zb-CdSe at Gamma point (eV): \n",
    "Eref_zbCdSe_Gamma = torch.tensor([-20.1798943671376740, -20.1798943671376740, -6.3095256693774902, -6.3095256693774902, -6.3095256693768960, \n",
    "                     -6.3095256693768960, -6.3024330398428914, -6.3024330398428914, -4.4148875987097256, -4.4148875987097256, \n",
    "                     1.3233415397783173, 1.3233415397783173, 1.3233415397789470, 1.3233415397789470, 1.3235075638553759, \n",
    "                     1.3235075638553759], dtype=torch.float64)\n",
    "\n",
    "# zb-CdSe for all k points\n",
    "Eref_zbCdSe = torch.tensor(np.loadtxt(\"bandStruct_zbCdSe.par\")[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd02c2c-76ea-41ce-a5e1-583ca14c509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBandStruct(bandStruct_array, marker_array, label_array): \n",
    "    fig, axs = plt.subplots(1,1, figsize=(3,3))\n",
    "    for bandStructIndex in range(len(bandStruct_array)): \n",
    "        numBands = len(bandStruct_array[bandStructIndex][0])\n",
    "        numKpts = len(bandStruct_array[bandStructIndex])\n",
    "        for i in range(numBands): \n",
    "            if i==0: \n",
    "                axs.plot(np.arange(numKpts), bandStruct_array[bandStructIndex][:, i].detach().numpy(), marker_array[bandStructIndex], label=label_array[bandStructIndex])\n",
    "            else: \n",
    "                axs.plot(np.arange(numKpts), bandStruct_array[bandStructIndex][:, i].detach().numpy(), marker_array[bandStructIndex])\n",
    "    axs.legend(frameon=False)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def pot_func(x, params): \n",
    "    pot = (params[0]*(x*x - params[1]) / (params[2] * np.exp(params[3]*x*x) - 1.0))\n",
    "    return pot\n",
    "    \n",
    "def plotPP(q_array, vq_Cd_array, vq_Se_array, label_array, lineshape_array): \n",
    "    fig, axs = plt.subplots(1,1, figsize=(3,3))\n",
    "    for i in range(len(vq_Cd_array)): \n",
    "        q = q_array[i].detach().numpy()\n",
    "        vq_Cd = vq_Cd_array[i].detach().numpy()\n",
    "        vq_Se = vq_Se_array[i].detach().numpy()\n",
    "        axs.plot(q, vq_Cd, lineshape_array[i], label=\"Cd \"+label_array[i])\n",
    "        axs.plot(q, vq_Se, lineshape_array[i], label=\"Se \"+label_array[i])\n",
    "    axs.set(xlabel=r\"$q$\", ylabel=r\"$v(q)$\")\n",
    "    axs.legend(frameon=False)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59cb3c09-e9f2-4389-9264-dbe61b58e12b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0331,  0.6281],\n",
      "        [-1.2901, -0.0408]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 20])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_463271/3012245182.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# print(\"\\nmodel.state_dict():\\n \", PPmodel.state_dict())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPPmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPPmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/perlmutter/3.9-anaconda-2021.11/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_463271/3012245182.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/perlmutter/3.9-anaconda-2021.11/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/perlmutter/3.9-anaconda-2021.11/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[0;32m--> 171\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/perlmutter/3.9-anaconda-2021.11/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2446\u001b[0m         )\n\u001b[1;32m   2447\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2448\u001b[0;31m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m     return torch.batch_norm(\n",
      "\u001b[0;32m~/.local/perlmutter/3.9-anaconda-2021.11/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 20])"
     ]
    }
   ],
   "source": [
    "# Create Net model class\n",
    "'''\n",
    "class Net(nn.Module):\n",
    "    # Constructor\n",
    "    def __init__(self, Layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "        self.batch_norm = nn.ModuleList()\n",
    "        for input_size, output_size in zip(Layers, Layers[1:]):\n",
    "            layer = nn.Linear(input_size, output_size, dtype=torch.float64)\n",
    "            init.xavier_normal_(layer.weight)\n",
    "            init.constant_(layer.bias, 0)\n",
    "            self.hidden.append(layer)\n",
    "            if output_size != Layers[-1]:\n",
    "                self.batch_norm.append(nn.BatchNorm1d(output_size, dtype=torch.float64))\n",
    "    # Prediction\n",
    "    def forward(self, activation):\n",
    "        L = len(self.hidden)\n",
    "        for (l, linear_transform) in enumerate(self.hidden):\n",
    "            if l < L - 1:\n",
    "                activation = torch.relu(linear_transform(activation))\n",
    "                activation = self.batch_norm[l](activation)\n",
    "            else:\n",
    "                activation = linear_transform(activation)\n",
    "        return activation\n",
    "\n",
    "Layers = [1, 20, 2]\n",
    "PPmodel = Net(Layers)\n",
    "'''\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Linear(1, 20, dtype=torch.float64) \n",
    "        self.bn1 = nn.BatchNorm1d(20, dtype=torch.float64) \n",
    "\n",
    "        self.hidden_layer1 = nn.Linear(20, 20, dtype=torch.float64) \n",
    "        self.bn2 = nn.BatchNorm1d(20, dtype=torch.float64)  \n",
    "\n",
    "        self.hidden_layer2 = nn.Linear(20, 20, dtype=torch.float64) \n",
    "        self.bn3 = nn.BatchNorm1d(20, dtype=torch.float64) \n",
    "\n",
    "        self.output_layer = nn.Linear(20, 2, dtype=torch.float64) \n",
    "\n",
    "        # Xavier initialization for weights\n",
    "        init.xavier_normal_(self.input_layer.weight)\n",
    "        init.xavier_normal_(self.hidden_layer1.weight)\n",
    "        init.xavier_normal_(self.hidden_layer2.weight)\n",
    "        init.xavier_normal_(self.output_layer.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.input_layer(x)))  \n",
    "        x = torch.relu(self.bn2(self.hidden_layer1(x)))\n",
    "        x = torch.relu(self.bn3(self.hidden_layer2(x)))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "PPmodel = Net()\n",
    "\n",
    "\n",
    "# print(\"list(model.parameters()):\\n \", list(PPmodel.parameters()))\n",
    "# print(\"\\nmodel.state_dict():\\n \", PPmodel.state_dict())\n",
    "print(PPmodel(torch.tensor([[1.0], [2.0]], dtype=torch.float64)))\n",
    "# print(PPmodel(torch.tensor([[1.0]], dtype=torch.float64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fdbc3-d7a8-4cab-9d20-51c6245fa4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nSystem = 1\n",
    "\n",
    "# read system\n",
    "scale = 11.4485278\n",
    "unitCellVector1 = torch.tensor([0.0, 0.5, 0.5], dtype=torch.float64) * scale\n",
    "unitCellVector2 = torch.tensor([0.5, 0.0, 0.5], dtype=torch.float64) * scale\n",
    "unitCellVector3 = torch.tensor([0.5, 0.5, 0.0], dtype=torch.float64) * scale\n",
    "unitCellVectors = torch.cat((unitCellVector1.unsqueeze(0), unitCellVector2.unsqueeze(0), unitCellVector3.unsqueeze(0)), dim=0)\n",
    "cellVolume = torch.dot(unitCellVector1, torch.cross(unitCellVector2, unitCellVector3))\n",
    "# print(cellVolume)\n",
    "\n",
    "prefactor = 2 * np.pi / cellVolume\n",
    "gVector1 = prefactor * torch.cross(unitCellVectors[1], unitCellVectors[2])\n",
    "gVector2 = prefactor * torch.cross(unitCellVectors[2], unitCellVectors[0])\n",
    "gVector3 = prefactor * torch.cross(unitCellVectors[0], unitCellVectors[1])\n",
    "gVectors = torch.cat((gVector1.unsqueeze(0), gVector2.unsqueeze(0), gVector3.unsqueeze(0)), dim=0)\n",
    "\n",
    "nAtoms = 2\n",
    "atomTypes = np.array([\"Cd\", \"Se\"])\n",
    "atomPos = torch.tensor([[0.125, 0.125, 0.125],\n",
    "                        [-0.125, -0.125, -0.125]], dtype=torch.float64)\n",
    "atomPos = atomPos @ unitCellVectors\n",
    "# print(atomPos)\n",
    "\n",
    "# read kPoints\n",
    "kpt_zbCdSe = torch.tensor(np.loadtxt(\"ZB_kpoints.par\"))\n",
    "kpt_zbCdSe = kpt_zbCdSe @ gVectors\n",
    "nkpt = kpt_zbCdSe.shape[0]\n",
    "\n",
    "Gamma = torch.tensor([0.0, 0.0, 0.0], dtype=torch.float64)\n",
    "\n",
    "maxKE = 10\n",
    "\n",
    "nBands = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ddb09-9df6-4142-a406-29731f00bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basis(maxKE, scale, unitCellVectors, cellVolume): \n",
    "    prefactor = 2 * np.pi / cellVolume\n",
    "    \n",
    "    gVector1 = prefactor * torch.cross(unitCellVectors[1], unitCellVectors[2])\n",
    "    gVector2 = prefactor * torch.cross(unitCellVectors[2], unitCellVectors[0])\n",
    "    gVector3 = prefactor * torch.cross(unitCellVectors[0], unitCellVectors[1])\n",
    "    # print(gVector1, gVector2, gVector3)\n",
    "    minGMag = min(torch.norm(gVector1), torch.norm(gVector2), torch.norm(gVector3))\n",
    "    numMaxBasisVectors = int(np.sqrt(2*maxKE) / minGMag)\n",
    "    # print(numMaxBasisVectors)\n",
    "\n",
    "    k = torch.arange(-numMaxBasisVectors, numMaxBasisVectors+1, dtype=torch.float64).repeat((2*numMaxBasisVectors+1)**2)\n",
    "    j = torch.arange(-numMaxBasisVectors, numMaxBasisVectors+1, dtype=torch.float64).repeat_interleave((2*numMaxBasisVectors+1)).repeat((2*numMaxBasisVectors+1))\n",
    "    i = torch.arange(-numMaxBasisVectors, numMaxBasisVectors+1, dtype=torch.float64).repeat_interleave((2*numMaxBasisVectors+1)**2)\n",
    "    allGrid = torch.vstack((i, j, k)).T\n",
    "    transform = torch.vstack((gVector1, gVector2, gVector3)).T\n",
    "    allBasisSet = allGrid @ transform\n",
    "    # print(allBasisSet.shape[0])\n",
    "    # print(allBasisSet)\n",
    "\n",
    "    row_norms = torch.norm(allBasisSet, dim=1)\n",
    "    condition = (HBAR*0.5*row_norms**2 / MASS < maxKE)\n",
    "    indices = torch.where(condition)[0]\n",
    "    basisSet = allBasisSet[indices]\n",
    "    # print(basisSet.shape[0])\n",
    "    # print(basisSet)\n",
    "    \n",
    "    sorting_indices = torch.argsort(basisSet[:, 2], stable=True)\n",
    "    basisSet = basisSet[sorting_indices]\n",
    "    sorting_indices = torch.argsort(basisSet[:, 1], stable=True)\n",
    "    basisSet = basisSet[sorting_indices]\n",
    "    sorting_indices = torch.argsort(basisSet[:, 0], stable=True)\n",
    "    basisSet = basisSet[sorting_indices]\n",
    "    row_norms = torch.norm(basisSet, dim=1)\n",
    "    sorting_indices = torch.argsort(row_norms[:], stable=True)\n",
    "    sorted_basisSet = basisSet[sorting_indices]\n",
    "\n",
    "    '''\n",
    "    sorting_indices1 = np.lexsort((basisSet[:, 2], basisSet[:, 1], basisSet[:, 0], row_norms))    \n",
    "    sorted_basisSet1 = basisSet[sorting_indices1]\n",
    "    print(torch.equal(sorted_basisSet1, sorted_basisSet))\n",
    "    print(torch.allclose(sorted_basisSet1, sorted_basisSet, atol=1e-5))\n",
    "    '''\n",
    "    return sorted_basisSet\n",
    "\n",
    "# construct hamiltonian at a certain k-point (kVector). Quicker through vectorization. \n",
    "def calcHamiltonianMatrix_NN(basisStates, kVector, nAtoms, cellVolume):\n",
    "    n = basisStates.shape[0]\n",
    "    HMatrix = torch.zeros((n, n), dtype=torch.complex128)\n",
    "\n",
    "    # Kinetic energy\n",
    "    for i in range(n): \n",
    "        HMatrix[i,i] += HBAR**2 / (2*MASS) * (torch.norm(basisStates[i] + kVector))**2\n",
    "        \n",
    "    # Local potential\n",
    "    gDiff = torch.stack([basisStates] * (basisStates.shape[0]), dim=1) - basisStates.repeat(basisStates.shape[0], 1, 1)\n",
    "    \n",
    "    for k in range(nAtoms): \n",
    "        gDiffDotTau = torch.sum(gDiff * atomPos[k], axis=2)\n",
    "        structFact = 1/cellVolume * (torch.cos(gDiffDotTau) + 1j*torch.sin(gDiffDotTau))\n",
    "\n",
    "        thisAtomIndex = np.where(atomTypes[k]==PP_order)[0]\n",
    "        if len(thisAtomIndex)!=1: \n",
    "            raise ValueError(\"Type of atoms in PP. \")\n",
    "        thisAtomIndex = thisAtomIndex[0]\n",
    "        \n",
    "        atomFF = PPmodel(torch.norm(gDiff, dim=2).view(-1, 1))\n",
    "        atomFF = atomFF[:, thisAtomIndex].view(n, n)\n",
    "        # atomFF = pot_func(torch.norm(gDiff, dim=2), totalParams[thisAtomIndex])\n",
    "        \n",
    "        HMatrix += atomFF * structFact\n",
    "    return HMatrix\n",
    "\n",
    "def calcBandStruct(basisStates, nkpt, kpts_coord, nAtoms, cellVolume, nBands): \n",
    "    bandStruct = torch.zeros((nkpt, nBands), dtype=torch.float64)\n",
    "    for kpt_index in range(nkpt): \n",
    "        HamiltonianMatrixAtKpt = calcHamiltonianMatrix_NN(basisStates, kpts_coord[kpt_index], nAtoms, cellVolume)\n",
    "\n",
    "        # diagonalize the hamiltonian\n",
    "        energies = torch.linalg.eigvalsh(HamiltonianMatrixAtKpt)\n",
    "        \n",
    "        energiesEV = energies * AUTOEV\n",
    "        # 2-fold degeneracy due to spin\n",
    "        final_energies = energiesEV.repeat_interleave(2)[:nBands]\n",
    "    \n",
    "        bandStruct[kpt_index] = final_energies\n",
    "\n",
    "    return bandStruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8496d01b-a852-4c4c-9d4e-43454455a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating on the initialized NN model\n",
    "\n",
    "# PPmodel(torch.tensor([[1.0], [2.0]], dtype=torch.float64))\n",
    "NN_init = PPmodel(qGrid.view(-1, 1))\n",
    "\n",
    "CdParams = torch.tensor([-31.4518, 1.3890, -0.0502, 1.6603, 0.0586], dtype=torch.float64)\n",
    "SeParams = torch.tensor([8.4921, 4.3513, 1.3600, 0.3227, 0.1746], dtype=torch.float64)\n",
    "SParams = torch.tensor([7.6697, 4.5192, 1.3456, 0.3035, 0.2087], dtype=torch.float64)\n",
    "PP_order = np.array([\"Cd\", \"Se\", \"S\"])\n",
    "totalParams = torch.cat((CdParams.unsqueeze(0), SeParams.unsqueeze(0), SParams.unsqueeze(0)), dim=0)\n",
    "\n",
    "CdPP = pot_func(qGrid, CdParams)\n",
    "SePP = pot_func(qGrid, SeParams)\n",
    "# totalPP = torch.cat((CdPP.unsqueeze(0), SePP.unsqueeze(0)), dim=0)\n",
    "plotPP([qGrid, qGrid], [CdPP, NN_init[:, 0]], [SePP, NN_init[:, 1]], [\"ZungerForm\", \"NN_init\"], [\"-\", \":\"])\n",
    "\n",
    "\n",
    "basisStates = basis(maxKE, scale, unitCellVectors, cellVolume)\n",
    "\n",
    "NN_init_BandStruct = calcBandStruct(basisStates, nkpt, kpt_zbCdSe, nAtoms, cellVolume, nBands)\n",
    "plotBandStruct([Eref_zbCdSe, NN_init_BandStruct], [\"bo\", \"r-\"], [\"Reference zbCdSe\", \"NN_init\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ea769c-336c-4d20-9a3b-6cf0b379941e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 2\n",
    "optimizer = torch.optim.Adam(PPmodel.parameters(), lr = learning_rate)\n",
    "\n",
    "basisStates = basis(maxKE, scale, unitCellVectors, cellVolume)\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "def train_model(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        # for name, param in PPmodel.named_parameters():\n",
    "        #     print(f\"Parameter: {name}, Size: {param.size()}\")\n",
    "        #     print(param.data)\n",
    "        NN_BandStruct = calcBandStruct(basisStates, nkpt, kpt_zbCdSe, nAtoms, cellVolume, nBands)\n",
    "        plotBandStruct([Eref_zbCdSe, NN_BandStruct], [\"bo\", \"r-\"], [\"Reference zbCdSe\", \"NN_\"+str(epoch)])\n",
    "        loss = ((Eref_zbCdSe - NN_BandStruct) ** 2).mean()\n",
    "        print(f\"Loss: {loss}\")\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for name, param in PPmodel.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                print(f\"Parameter: {name}, Gradient Norm: {param.grad.norm().item()}\")\n",
    "        optimizer.step()\n",
    "\n",
    "train_model(30)\n",
    "\n",
    "NN_latest = PPmodel(qGrid.view(-1, 1))\n",
    "plotPP([qGrid, qGrid], [CdPP, NN_latest[:, 0]], [SePP, NN_latest[:, 1]], [\"ZungerForm\", \"NN_latest\"], [\"-\", \":\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43fe107-0dd5-470c-ae0a-d17292376233",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(50)\n",
    "\n",
    "NN_latest = PPmodel(qGrid.view(-1, 1))\n",
    "plotPP([qGrid, qGrid], [CdPP, NN_latest[:, 0]], [SePP, NN_latest[:, 1]], [\"ZungerForm\", \"NN_latest\"], [\"-\", \":\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
